<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.1">
<link rel="alternate" type="application/rss+xml" href="/mobile-ds/blog/rss.xml" title="PyTorch Mobile Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/mobile-ds/blog/atom.xml" title="PyTorch Mobile Blog Atom Feed"><title data-react-helmet="true">Pytorch Mobile Performance Recipes | PyTorch Mobile</title><meta data-react-helmet="true" property="og:url" content="https://brianjo.github.com/mobile-ds/docs/performance/mobile_perf"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Pytorch Mobile Performance Recipes | PyTorch Mobile"><meta data-react-helmet="true" name="description" content="Introduction"><meta data-react-helmet="true" property="og:description" content="Introduction"><link data-react-helmet="true" rel="shortcut icon" href="/mobile-ds/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://brianjo.github.com/mobile-ds/docs/performance/mobile_perf"><link data-react-helmet="true" rel="alternate" href="https://brianjo.github.com/mobile-ds/docs/performance/mobile_perf" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://brianjo.github.com/mobile-ds/docs/performance/mobile_perf" hreflang="x-default"><link rel="stylesheet" href="/mobile-ds/assets/css/styles.f84ef0c2.css">
<link rel="preload" href="/mobile-ds/assets/js/runtime~main.61ebeb0e.js" as="script">
<link rel="preload" href="/mobile-ds/assets/js/main.fec1926f.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#main" class="skipToContent_1oUP shadow--md">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/mobile-ds/"><img src="/mobile-ds/img/logo.svg" alt="PyTorch" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/mobile-ds/img/logo.svg" alt="PyTorch" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><b class="navbar__title">PyTorch Mobile</b></a><a class="navbar__item navbar__link navbar__link--active" href="/mobile-ds/docs/intro">Documentation</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/mobile-ds/"><img src="/mobile-ds/img/logo.svg" alt="PyTorch" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/mobile-ds/img/logo.svg" alt="PyTorch" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><b class="navbar__title">PyTorch Mobile</b></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link navbar__link--active" href="/mobile-ds/docs/intro">Documentation</a></li><li class="menu__list-item"><a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener noreferrer" class="menu__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div></div></nav><div class="main-wrapper docs-wrapper doc-page"><div class="docPage_31aa"><aside class="docSidebarContainer_3Kbt"><div class="sidebar_15mo"><nav class="menu menu--responsive thin-scrollbar menu_Bmed" aria-label="Sidebar navigation"><button aria-label="Open menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg class="sidebarMenuIcon_fgN0" width="24" height="24" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/mobile-ds/docs/intro">PyTorch Mobile</a></li><li class="menu__list-item"><a class="menu__link" href="/mobile-ds/docs/helloworld">Hello World!</a></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Model Preparation</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/mobile-ds/docs/modelprep/interpreters">Lite and Full Jit Interpreters</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/mobile-ds/docs/modelprep/optimization">Script and Optimize for Mobile</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/mobile-ds/docs/modelprep/quantization">Quantization</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Build from Source</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/mobile-ds/docs/building/android_native_app_with_custom_op">Making a Native Android Application that uses PyTorch prebuilt libraries</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/mobile-ds/docs/building/androidbuild">Building PyTorch Android from Source</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/mobile-ds/docs/building/iosbuild">Build PyTorch iOS Libraries from Source</a></li></ul></li><li class="menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#!">Performance</a><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/mobile-ds/docs/performance/mobile_perf">Pytorch Mobile Performance Recipes</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Tutorials</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/mobile-ds/docs/tutorials/overview">Overview</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Videos</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/mobile-ds/docs/videos/overview">Getting Started</a></li></ul></li><li class="menu__list-item"><a class="menu__link" href="/mobile-ds/docs/android">Android</a></li><li class="menu__list-item"><a class="menu__link" href="/mobile-ds/docs/ios">iOS</a></li></ul></nav></div></aside><main class="docMainContainer_3ufF"><div class="container padding-top--md padding-bottom--lg docItemWrapper_3FMP"><div class="row"><div class="col docItemCol_3FnS"><div class="docItemContainer_33ec"><article><div class="markdown"><header><h1 class="h1Heading_27L5">Pytorch Mobile Performance Recipes</h1></header><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="introduction"></a>Introduction<a class="hash-link" href="#introduction" title="Direct link to heading">#</a></h2><p>Performance (aka latency) is crucial to most, if not all, applications
and use-cases of ML model inference on mobile devices.</p><p>Today, PyTorch executes the models on the CPU backend pending
availability of other hardware backends such as GPU, DSP, and NPU.</p><p>In this recipe, you will learn:</p><ul><li>How to optimize your model to help decrease execution time (higher
performance, lower latency) on the mobile device.</li><li>How to benchmark (to check if optimizations helped your use case).</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="model-preparation"></a>Model preparation<a class="hash-link" href="#model-preparation" title="Direct link to heading">#</a></h2><p>We will start with preparing to optimize your model to help decrease
execution time (higher performance, lower latency) on the mobile device.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="setup"></a>Setup<a class="hash-link" href="#setup" title="Direct link to heading">#</a></h3><p>First we need to installed pytorch using conda or pip with version at
least 1.5.0.</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">conda install pytorch torchvision -c pytorch</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>or</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">pip install torch torchvision</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Code your model:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">import torch</span></span><span class="token-line" style="color:#393A34"><span class="token plain">from torch.utils.mobile_optimizer import optimize_for_mobile</span></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#393A34"><span class="token plain">class AnnotatedConvBnReLUModel(torch.nn.Module):</span></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self):</span></span><span class="token-line" style="color:#393A34"><span class="token plain">        super(AnnotatedConvBnReLUModel, self).__init__()</span></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.conv = torch.nn.Conv2d(3, 5, 3, bias=False).to(dtype=torch.float)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.bn = torch.nn.BatchNorm2d(5).to(dtype=torch.float)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.relu = torch.nn.ReLU(inplace=True)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.quant = torch.quantization.QuantStub()</span></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.dequant = torch.quantization.DeQuantStub()</span></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#393A34"><span class="token plain">    def forward(self, x):</span></span><span class="token-line" style="color:#393A34"><span class="token plain">        x.contiguous(memory_format=torch.channels_last)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">        x = self.quant(x)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">        x = self.conv(x)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">        x = self.bn(x)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">        x = self.relu(x)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">        x = self.dequant(x)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">        return x</span></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#393A34"><span class="token plain">model = AnnotatedConvBnReLUModel()</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p><code>torch.quantization.QuantStub</code> and <code>torch.quantization.DeQuantStub()</code>
are no-op stubs, which will be used for quantization step.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="1-fuse-operators-using-torchquantizationfuse_modules"></a>1. Fuse operators using <code>torch.quantization.fuse_modules</code><a class="hash-link" href="#1-fuse-operators-using-torchquantizationfuse_modules" title="Direct link to heading">#</a></h3><p>Do not be confused that fuse_modules is in the quantization package. It
works for all <code>torch.nn.Module</code>.</p><p><code>torch.quantization.fuse_modules</code> fuses a list of modules into a single
module. It fuses only the following sequence of modules:</p><ul><li>Convolution, Batch normalization</li><li>Convolution, Batch normalization, Relu</li><li>Convolution, Relu</li><li>Linear, Relu</li></ul><p>This script will fuse Convolution, Batch Normalization and Relu in
previously declared model.</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">torch.quantization.fuse_modules(model, [[&#x27;conv&#x27;, &#x27;bn&#x27;, &#x27;relu&#x27;]], inplace=True)</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="2-quantize-your-model"></a>2. Quantize your model<a class="hash-link" href="#2-quantize-your-model" title="Direct link to heading">#</a></h3><p>You can find more about PyTorch quantization in <a href="https://pytorch.org/blog/introduction-to-quantization-on-pytorch/" target="_blank" rel="noopener noreferrer">the dedicated
tutorial</a>.</p><p>Quantization of the model not only moves computation to int8, but also
reduces the size of your model on a disk. That size reduction helps to
reduce disk read operations during the first load of the model and
decreases the amount of RAM. Both of those resources can be crucial for
the performance of mobile applications. This code does quantization,
using stub for model calibration function, you can find more about it
<a href="https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html#post-training-static-quantization" target="_blank" rel="noopener noreferrer">here</a>.</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">model.qconfig = torch.quantization.get_default_qconfig(&#x27;qnnpack&#x27;)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">torch.quantization.prepare(model, inplace=True)</span></span><span class="token-line" style="color:#393A34"><span class="token plain"># Calibrate your model</span></span><span class="token-line" style="color:#393A34"><span class="token plain">def calibrate(model, calibration_data):</span></span><span class="token-line" style="color:#393A34"><span class="token plain">    # Your calibration code here</span></span><span class="token-line" style="color:#393A34"><span class="token plain">    return</span></span><span class="token-line" style="color:#393A34"><span class="token plain">calibrate(model, [])</span></span><span class="token-line" style="color:#393A34"><span class="token plain">torch.quantization.convert(model, inplace=True)</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="3-use-torchutilsmobile_optimizer"></a>3. Use torch.utils.mobile_optimizer<a class="hash-link" href="#3-use-torchutilsmobile_optimizer" title="Direct link to heading">#</a></h3><p>Torch mobile_optimizer package does several optimizations with the
scripted model, which will help to conv2d and linear operations. It
pre-packs model weights in an optimized format and fuses ops above with
relu if it is the next operation.</p><p>First we script the result model from previous step:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">torchscript_model = torch.jit.script(model)</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Next we call <code>optimize_for_mobile</code> and save model on the disk.</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">torchscript_model_optimized = optimize_for_mobile(torchscript_model)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">torch.jit.save(torchscript_model_optimized, &quot;model.pt&quot;)</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="4-prefer-using-channels-last-tensor-memory-format"></a>4. Prefer Using Channels Last Tensor memory format<a class="hash-link" href="#4-prefer-using-channels-last-tensor-memory-format" title="Direct link to heading">#</a></h3><p>Channels Last(NHWC) memory format was introduced in PyTorch 1.4.0. It is
supported only for four-dimensional tensors. This memory format gives a
better memory locality for most operators, especially convolution. Our
measurements showed a 3x speedup of MobileNetV2 model compared with the
default Channels First(NCHW) format.</p><p>At the moment of writing this recipe, PyTorch Android java API does not
support using inputs in Channels Last memory format. But it can be used
on the TorchScript model level, by adding the conversion to it for model
inputs.</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">def forward(self, x):</span></span><span class="token-line" style="color:#393A34"><span class="token plain">    x.contiguous(memory_format=torch.channels_last)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">    ...</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>This conversion is zero cost if your input is already in Channels Last
memory format. After it, all operators will work preserving ChannelsLast
memory format.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="5-android---reusing-tensors-for-forward"></a>5. Android - Reusing tensors for forward<a class="hash-link" href="#5-android---reusing-tensors-for-forward" title="Direct link to heading">#</a></h3><p>This part of the recipe is Android only.</p><p>Memory is a critical resource for android performance, especially on old
devices. Tensors can need a significant amount of memory. For example,
standard computer vision tensor contains 1*3*224*224 elements,
assuming that data type is float and will need 588Kb of memory.</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">FloatBuffer buffer = Tensor.allocateFloatBuffer(1*3*224*224);</span></span><span class="token-line" style="color:#393A34"><span class="token plain">Tensor tensor = Tensor.fromBlob(buffer, new long[]{1, 3, 224, 224});</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Here we allocate native memory as <code>java.nio.FloatBuffer</code> and creating
<code>org.pytorch.Tensor</code> which storage will be pointing to the memory of the
allocated buffer.</p><p>For most of the use cases, we do not do model forward only once,
repeating it with some frequency or as fast as possible.</p><p>If we are doing new memory allocation for every module forward - that
will be suboptimal. Instead of this, we can reuse the same memory that
we allocated on the previous step, fill it with new data, and run module
forward again on the same tensor object.</p><p>You can check how it looks in code in <a href="https://github.com/pytorch/android-demo-app/blob/master/PyTorchDemoApp/app/src/main/java/org/pytorch/demo/vision/ImageClassificationActivity.java#L174" target="_blank" rel="noopener noreferrer">pytorch android application
example</a>.</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">protected AnalysisResult analyzeImage(ImageProxy image, int rotationDegrees) {</span></span><span class="token-line" style="color:#393A34"><span class="token plain">  if (mModule == null) {</span></span><span class="token-line" style="color:#393A34"><span class="token plain">    mModule = Module.load(moduleFileAbsoluteFilePath);</span></span><span class="token-line" style="color:#393A34"><span class="token plain">    mInputTensorBuffer =</span></span><span class="token-line" style="color:#393A34"><span class="token plain">    Tensor.allocateFloatBuffer(3 * 224 * 224);</span></span><span class="token-line" style="color:#393A34"><span class="token plain">    mInputTensor = Tensor.fromBlob(mInputTensorBuffer, new long[]{1, 3, 224, 224});</span></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#393A34"><span class="token plain">  TensorImageUtils.imageYUV420CenterCropToFloatBuffer(</span></span><span class="token-line" style="color:#393A34"><span class="token plain">      image.getImage(), rotationDegrees,</span></span><span class="token-line" style="color:#393A34"><span class="token plain">      224, 224,</span></span><span class="token-line" style="color:#393A34"><span class="token plain">      TensorImageUtils.TORCHVISION_NORM_MEAN_RGB,</span></span><span class="token-line" style="color:#393A34"><span class="token plain">      TensorImageUtils.TORCHVISION_NORM_STD_RGB,</span></span><span class="token-line" style="color:#393A34"><span class="token plain">      mInputTensorBuffer, 0);</span></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#393A34"><span class="token plain">  Tensor outputTensor = mModule.forward(IValue.from(mInputTensor)).toTensor();</span></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Member fields <code>mModule</code>, <code>mInputTensorBuffer</code> and <code>mInputTensor</code> are
initialized only once and buffer is refilled using
<code>org.pytorch.torchvision.TensorImageUtils.imageYUV420CenterCropToFloatBuffer</code>.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="benchmarking"></a>Benchmarking<a class="hash-link" href="#benchmarking" title="Direct link to heading">#</a></h2><p>The best way to benchmark (to check if optimizations helped your use
case) - is to measure your particular use case that you want to
optimize, as performance behavior can vary in different environments.</p><p>PyTorch distribution provides a way to benchmark naked binary that runs
the model forward, this approach can give more stable measurements
rather than testing inside the application.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="android---benchmarking-setup"></a>Android - Benchmarking Setup<a class="hash-link" href="#android---benchmarking-setup" title="Direct link to heading">#</a></h3><p>This part of the recipe is Android only.</p><p>For this you first need to build benchmark binary:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">&lt;from-your-root-pytorch-dir&gt;</span></span><span class="token-line" style="color:#393A34"><span class="token plain">rm -rf build_android</span></span><span class="token-line" style="color:#393A34"><span class="token plain">BUILD_PYTORCH_MOBILE=1 ANDROID_ABI=arm64-v8a ./scripts/build_android.sh -DBUILD_BINARY=ON</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>You should have arm64 binary at:
<code>build_android/bin/speed_benchmark_torch</code>. This binary takes
<code>--model=&lt;path-to-model&gt;</code>, <code>--input_dim=&quot;1,3,224,224&quot;</code> as dimension
information for the input and <code>--input_type=&quot;float&quot;</code> as the type of the
input as arguments.</p><p>Once you have your android device connected, push speedbenchark_torch
binary and your model to the phone:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">adb push &lt;speedbenchmark-torch&gt; /data/local/tmp</span></span><span class="token-line" style="color:#393A34"><span class="token plain">adb push &lt;path-to-scripted-model&gt; /data/local/tmp</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Now we are ready to benchmark your model:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">adb shell &quot;/data/local/tmp/speed_benchmark_torch --model=/data/local/tmp/model.pt&quot; --input_dims=&quot;1,3,224,224&quot; --input_type=&quot;float&quot;</span></span><span class="token-line" style="color:#393A34"><span class="token plain">----- output -----</span></span><span class="token-line" style="color:#393A34"><span class="token plain">Starting benchmark.</span></span><span class="token-line" style="color:#393A34"><span class="token plain">Running warmup runs.</span></span><span class="token-line" style="color:#393A34"><span class="token plain">Main runs.</span></span><span class="token-line" style="color:#393A34"><span class="token plain">Main run finished. Microseconds per iter: 121318. Iters per second: 8.24281</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="ios---benchmarking-setup"></a>iOS - Benchmarking Setup<a class="hash-link" href="#ios---benchmarking-setup" title="Direct link to heading">#</a></h3><p>For iOS, we&#x27;ll be using our
<a href="https://github.com/pytorch/pytorch/tree/master/ios/TestApp" target="_blank" rel="noopener noreferrer">TestApp</a> as
the benchmarking tool.</p><p>To begin with, let&#x27;s apply the <code>optimize_for_mobile</code> method to our
python script located at
<a href="https://github.com/pytorch/pytorch/blob/master/ios/TestApp/benchmark/trace_model.py" target="_blank" rel="noopener noreferrer">TestApp/benchmark/trace_model.py</a>.
Simply modify the code as below.</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">import torch</span></span><span class="token-line" style="color:#393A34"><span class="token plain">import torchvision</span></span><span class="token-line" style="color:#393A34"><span class="token plain">from torch.utils.mobile_optimizer import optimize_for_mobile</span></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></span><span class="token-line" style="color:#393A34"><span class="token plain">model = torchvision.models.mobilenet_v2(pretrained=True)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">model.eval()</span></span><span class="token-line" style="color:#393A34"><span class="token plain">example = torch.rand(1, 3, 224, 224)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">traced_script_module = torch.jit.trace(model, example)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">torchscript_model_optimized = optimize_for_mobile(traced_script_module)</span></span><span class="token-line" style="color:#393A34"><span class="token plain">torch.jit.save(torchscript_model_optimized, &quot;model.pt&quot;)</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Now let&#x27;s run <code>python trace_model.py</code>. If everything works well, we
should be able to generate our optimized model in the benchmark
directory.</p><p>Next, we&#x27;re going to build the PyTorch libraries from source.</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">BUILD_PYTORCH_MOBILE=1 IOS_ARCH=arm64 ./scripts/build_ios.sh</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Now that we have the optimized model and PyTorch ready, it&#x27;s time to
generate our XCode project and do benchmarking. To do that, we&#x27;ll be
using a ruby script - <span class="title-ref">setup.rb</span> which does
the heavy lifting jobs of setting up the XCode project.</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">ruby setup.rb</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>Now open the <span class="title-ref">TestApp.xcodeproj</span> and plug
in your iPhone, you&#x27;re ready to go. Below is an example result from
iPhoneX</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#393A34"><span class="token plain">TestApp[2121:722447] Main runs</span></span><span class="token-line" style="color:#393A34"><span class="token plain">TestApp[2121:722447] Main run finished. Milliseconds per iter: 28.767</span></span><span class="token-line" style="color:#393A34"><span class="token plain">TestApp[2121:722447] Iters per second: : 34.762</span></span><span class="token-line" style="color:#393A34"><span class="token plain">TestApp[2121:722447] Done.</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div></div><footer class="row docusaurus-mt-lg"><div class="col"><a href="https://github.com/facebook/docusaurus/edit/master/website/docs/performance/mobile_perf.md" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_2_ui" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_3DPF"></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/mobile-ds/docs/building/iosbuild"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">« Build PyTorch iOS Libraries from Source</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/mobile-ds/docs/tutorials/overview"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Overview »</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link">Introduction</a></li><li><a href="#model-preparation" class="table-of-contents__link">Model preparation</a><ul><li><a href="#setup" class="table-of-contents__link">Setup</a></li><li><a href="#1-fuse-operators-using-torchquantizationfuse_modules" class="table-of-contents__link">1. Fuse operators using <code>torch.quantization.fuse_modules</code></a></li><li><a href="#2-quantize-your-model" class="table-of-contents__link">2. Quantize your model</a></li><li><a href="#3-use-torchutilsmobile_optimizer" class="table-of-contents__link">3. Use torch.utils.mobile_optimizer</a></li><li><a href="#4-prefer-using-channels-last-tensor-memory-format" class="table-of-contents__link">4. Prefer Using Channels Last Tensor memory format</a></li><li><a href="#5-android---reusing-tensors-for-forward" class="table-of-contents__link">5. Android - Reusing tensors for forward</a></li></ul></li><li><a href="#benchmarking" class="table-of-contents__link">Benchmarking</a><ul><li><a href="#android---benchmarking-setup" class="table-of-contents__link">Android - Benchmarking Setup</a></li><li><a href="#ios---benchmarking-setup" class="table-of-contents__link">iOS - Benchmarking Setup</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/mobile-ds/docs/intro">Documentation</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow</a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord</a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2021 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/mobile-ds/assets/js/runtime~main.61ebeb0e.js"></script>
<script src="/mobile-ds/assets/js/main.fec1926f.js"></script>
</body>
</html>