(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[614],{3905:function(e,t,r){"use strict";r.d(t,{Zo:function(){return p},kt:function(){return u}});var n=r(7294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var l=n.createContext({}),c=function(e){var t=n.useContext(l),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},p=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},h=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),h=c(r),u=o,m=h["".concat(l,".").concat(u)]||h[u]||d[u]||a;return r?n.createElement(m,i(i({ref:t},p),{},{components:r})):n.createElement(m,i({ref:t},p))}));function u(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=r.length,i=new Array(a);i[0]=h;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var c=2;c<a;c++)i[c]=r[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}h.displayName="MDXCreateElement"},8903:function(e,t,r){"use strict";r.r(t),r.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return c},toc:function(){return p},default:function(){return h}});var n=r(2122),o=r(9756),a=(r(7294),r(3905)),i=["components"],s={},l="Script and Optimize for Mobile",c={unversionedId:"modelprep/optimization",id:"modelprep/optimization",isDocsHomePage:!1,title:"Script and Optimize for Mobile",description:"This recipe demonstrates how to convert a PyTorch model to TorchScript",source:"@site/docs/modelprep/optimization.md",sourceDirName:"modelprep",slug:"/modelprep/optimization",permalink:"/mobile-ds/docs/modelprep/optimization",editUrl:"https://github.com/facebook/docusaurus/edit/master/website/docs/modelprep/optimization.md",version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Lite and Full Jit Interpreters",permalink:"/mobile-ds/docs/modelprep/interpreters"},next:{title:"Quantization",permalink:"/mobile-ds/docs/modelprep/quantization"}},p=[{value:"Introduction",id:"introduction",children:[]},{value:"Pre-requisites",id:"pre-requisites",children:[]},{value:"Conversion to TorchScript",id:"conversion-to-torchscript",children:[{value:'Use the <span class="title-ref">trace</span> Method',id:"use-the-trace-method",children:[]},{value:'Use the <span class="title-ref">script</span> Method',id:"use-the-script-method",children:[]}]},{value:'Fix Common Errors When Using the <span class="title-ref">script</span> Method',id:"fix-common-errors-when-using-the-script-method",children:[{value:'1. RuntimeError <span class="title-ref">attribute lookup is not defined on python value of type</span>',id:"1-runtimeerror-attribute-lookup-is-not-defined-on-python-value-of-type",children:[]},{value:'2. RuntimeError <span class="title-ref">python value of type &#39;...&#39; cannot be used as a value.</span>',id:"2-runtimeerror-python-value-of-type--cannot-be-used-as-a-value",children:[]},{value:'3. RuntimeError <span class="title-ref">all inputs of range must be &#39;...&#39;, found Tensor (inferred) in argument</span>',id:"3-runtimeerror-all-inputs-of-range-must-be--found-tensor-inferred-in-argument",children:[]}]},{value:"Optimize a TorchScript Model",id:"optimize-a-torchscript-model",children:[]},{value:"Learn More",id:"learn-more",children:[]}],d={toc:p};function h(e){var t=e.components,r=(0,o.Z)(e,i);return(0,a.kt)("wrapper",(0,n.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"script-and-optimize-for-mobile"},"Script and Optimize for Mobile"),(0,a.kt)("p",null,"This recipe demonstrates how to convert a PyTorch model to TorchScript\nwhich can run in a high-performance C++ environment such as iOS and\nAndroid, and how to optimize the converted TorchScript model for mobile\ndeployment."),(0,a.kt)("h2",{id:"introduction"},"Introduction"),(0,a.kt)("p",null,"After a PyTorch model is trained and optionally but preferably quantized\n(see ",(0,a.kt)("a",{parentName:"p",href:"quantization.html"},"Quantization Recipe")," for more details), one\nessential step before the model can be used in iOS and Android apps is\nto convert the Python-dependent model to TorchScript, which can then\nfurther be optimized for mobile apps. Conversion to TorchScript can be\nas simple as a single call, or as complicated as changing the original\nmodel in many different places."),(0,a.kt)("h2",{id:"pre-requisites"},"Pre-requisites"),(0,a.kt)("p",null,"PyTorch 1.6.0 or 1.7.0"),(0,a.kt)("h2",{id:"conversion-to-torchscript"},"Conversion to TorchScript"),(0,a.kt)("p",null,"There are two basic ways to convert a PyTorch model to TorchScript,\nusing ",(0,a.kt)("span",{class:"title-ref"},"trace")," and ",(0,a.kt)("span",{class:"title-ref"},"script"),". Mixing ",(0,a.kt)("span",{class:"title-ref"},"trace")," and ",(0,a.kt)("span",{class:"title-ref"},"script"),"\nmay also be needed in some cases - see\n",(0,a.kt)("a",{parentName:"p",href:"https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html#mixing-scripting-and-tracing"},"here"),"\nfor more information."),(0,a.kt)("h3",{id:"use-the-trace-method"},"Use the ",(0,a.kt)("span",{class:"title-ref"},"trace")," Method"),(0,a.kt)("p",null,"To use the ",(0,a.kt)("span",{class:"title-ref"},"trace")," method on a model, an\nexample or dummy input for the model needs to be specified, the actual\ninput size needs to be the same as the example input size, and the model\ndefinition cannot have control flow such as ",(0,a.kt)("span",{class:"title-ref"},"if")," or ",(0,a.kt)("span",{class:"title-ref"},"for"),". The\nreason for these constraints is that running ",(0,a.kt)("span",{class:"title-ref"},"trace")," on a model with an example input simply\ncalls the model's ",(0,a.kt)("span",{class:"title-ref"},"forward")," method with the\ninput and all operations executed in the model layers are recorded,\ncreating the trace of the model."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"import torch\n\ndummy_input = torch.rand(1, 3, 224, 224)\ntorchscript_model = torch.jit.trace(model_quantized, dummy_input)\n")),(0,a.kt)("h3",{id:"use-the-script-method"},"Use the ",(0,a.kt)("span",{class:"title-ref"},"script")," Method"),(0,a.kt)("p",null,"For the example above, calling ",(0,a.kt)("span",{class:"title-ref"},"script"),"\nbelow makes no difference:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"torchscript_model = torch.jit.script(model_quantized)\n")),(0,a.kt)("p",null,"But if a model has some flow control, then ",(0,a.kt)("span",{class:"title-ref"},"trace")," won't correctly record all the possible\ntraces. Take some code snippet of an example model definition from\n",(0,a.kt)("a",{parentName:"p",href:"https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html"},"here"),"\nfor example:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"import torch\n\nclass MyDecisionGate(torch.nn.Module):\n    def forward(self, x):\n        if x.sum() > 0:\n            return x\n        else:\n            return -x\n\nx = torch.rand(3, 4)\ntraced_cell = torch.jit.trace(MyDecisionGate(), x)\nprint(traced_cell.code)\n")),(0,a.kt)("p",null,"The code above will output:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"TracerWarning: Converting a tensor to a Python boolean might cause the trace \nto be incorrect. We can''t record the data flow of Python values, so this value \nwill be treated as a constant in the future. This means that the trace might \nnot generalize to other inputs!\n\nif x.sum() > 0:\ndef forward(self,\n  x: Tensor) -> Tensor:\nreturn x\n")),(0,a.kt)("p",null,'Note that "the trace might not generalize to other inputs" warning above\nmeans that if the model has any kind of data-dependent control flow,'),(0,a.kt)("span",{class:"title-ref"},"trace")," is not the right answer. But if we replace the last two lines of the Python code snippet above (before the code output) with:",(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"scripted_cell = torch.jit.script(MyDecisionGate())\nprint(scripted_cell.code)\n")),(0,a.kt)("p",null,"The scripted model as shown by the ",(0,a.kt)("span",{class:"title-ref"},"print"),"\nresult below will be covering all possible inputs, thus generalizing to\nother inputs:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"def forward(self,\n    x: Tensor) -> Tensor:\n  _0 = bool(torch.gt(torch.sum(x, dtype=None), 0))\n  if _0:\n    _1 = x\n  else:\n    _1 = torch.neg(x)\n  return _1\n")),(0,a.kt)("p",null,"This is another example of using ",(0,a.kt)("span",{class:"title-ref"},"trace"),"\nand ",(0,a.kt)("span",{class:"title-ref"},"script")," - it converts the model\ntrained in the PyTorch tutorial ",(0,a.kt)("a",{parentName:"p",href:"https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"},"NLP FROM SCRATCH: TRANSLATION WITH A\nSEQUENCE TO SEQUENCE NETWORK AND\nATTENTION"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"encoder = EncoderRNN(input_lang.n_words, hidden_size)\ndecoder = AttnDecoderRNN(hidden_size, output_lang.n_words)\n\n# method 1: using trace with example inputs\n\nencoder_input=torch.tensor([1])\nencoder_hidden=torch.zeros(1, 1, hidden_size)\n\ndecoder_input1=torch.tensor([[0]])\ndecoder_input2=torch.zeros(1, 1, hidden_size)\ndecoder_input3=torch.zeros(MAX_LENGTH, hidden_size)\n\ntraced_encoder = torch.jit.trace(encoder, (encoder_input, encoder_hidden))\ntraced_decoder = torch.jit.trace(decoder, (decoder_input1, decoder_input2, decoder_input3))\n\n# method 2: using script\n\nscripted_encoder = torch.jit.script(encoder)\nscripted_decoder = torch.jit.script(decoder)\n")),(0,a.kt)("p",null,"So is it true that one can simply always use the ",(0,a.kt)("span",{class:"title-ref"},"script")," call and the model is converted to\nTorchScript? The answer is no, because TorchScript is actually a subset\nof Python and to make ",(0,a.kt)("span",{class:"title-ref"},"script")," work, the\nPyTorch model definition must only use the language features of that\nTorchScript subset of Python. ",(0,a.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/master/jit_language_reference.html#language-reference"},"TorchScript Language\nReference"),"\ncovers all the details of what is supported in TorchScript. Below we\nwill describe some of the common errors when using the ",(0,a.kt)("span",{class:"title-ref"},"script")," method."),(0,a.kt)("h2",{id:"fix-common-errors-when-using-the-script-method"},"Fix Common Errors When Using the ",(0,a.kt)("span",{class:"title-ref"},"script")," Method"),(0,a.kt)("p",null,"If you apply the ",(0,a.kt)("span",{class:"title-ref"},"script")," method to a\nnon-trivial model, chances are you may encounter several types of\nerrors. Check out ",(0,a.kt)("a",{parentName:"p",href:"https://pytorch.org/tutorials/beginner/deploy_seq2seq_hybrid_frontend_tutorial.html"},"this\ntutorial"),"\nfor a complete example of converting a chatbot model to TorchScript. But\nfollow the steps below to fix common errors when you run the ",(0,a.kt)("span",{class:"title-ref"},"script")," method:"),(0,a.kt)("h3",{id:"1-runtimeerror-attribute-lookup-is-not-defined-on-python-value-of-type"},"1. RuntimeError ",(0,a.kt)("span",{class:"title-ref"},"attribute lookup is not defined on python value of type")),(0,a.kt)("p",null,"For this error, pass the value of the model as a parameter in the\nconstructor. This is because when calling ",(0,a.kt)("span",{class:"title-ref"},"script")," on a model that accepts another model as\na parameter, the model passed is actually of type ",(0,a.kt)("span",{class:"title-ref"},"TracedModule")," or ",(0,a.kt)("span",{class:"title-ref"},"ScriptModule"),", not of type ",(0,a.kt)("span",{class:"title-ref"},"Module"),", making the the model attribute not\ndefined when scripting."),(0,a.kt)("p",null,"For example, the ",(0,a.kt)("span",{class:"title-ref"},"LuongAttnDecoderRNN"),"\nmodule in the tutorial above has an attribute ",(0,a.kt)("span",{class:"title-ref"},"n","_","layers"),", and the ",(0,a.kt)("span",{class:"title-ref"},"GreedySearchDecoder")," module refers to the ",(0,a.kt)("span",{class:"title-ref"},"n","_","layers")," attribute of a ",(0,a.kt)("span",{class:"title-ref"},"decoder")," instance of the ",(0,a.kt)("span",{class:"title-ref"},"LuongAttnDecoderRNN")," module, so in order to make"),(0,a.kt)("span",{class:"title-ref"},"script")," work, the ",(0,a.kt)("span",{class:"title-ref"},"GreedySearchDecoder")," module's constructor needs to be changed from:",(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"def __init__(self, encoder, decoder):\n")),(0,a.kt)("p",null,"to:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"def __init__(self, encoder, decoder, decoder_n_layers):\n  ...\n  self._decoder_n_layers = decoder_n_layers\n")),(0,a.kt)("p",null,"and the ",(0,a.kt)("span",{class:"title-ref"},"GreedySearchDecoder"),"'s ",(0,a.kt)("span",{class:"title-ref"},"forward")," method needs to refer ",(0,a.kt)("span",{class:"title-ref"},"self.","_","decoder","_","n","_","layers")," instead of ",(0,a.kt)("span",{class:"title-ref"},"decoder.n","_","layers"),"."),(0,a.kt)("h3",{id:"2-runtimeerror-python-value-of-type--cannot-be-used-as-a-value"},"2. RuntimeError ",(0,a.kt)("span",{class:"title-ref"},"python value of type '...' cannot be used as a value.")),(0,a.kt)("p",null,"The complete error message for this one continues with ",(0,a.kt)("span",{class:"title-ref"},"Perhaps it is a closed over global variable? If so,\nplease consider passing it in as an argument or use a local variable\ninstead."),", store global variables' values as attributes in the\nmodel constructor (there's no need to add them to a special list called"),(0,a.kt)("span",{class:"title-ref"},"\\_\\_constants\\_\\_"),"). The reason is that global values can be used conveniently in normal model training and inference, but the global values are not accessible during the scripting.",(0,a.kt)("p",null,"For example, ",(0,a.kt)("span",{class:"title-ref"},"device")," and ",(0,a.kt)("span",{class:"title-ref"},"SOS","_","token")," are global variables, and to make"),(0,a.kt)("span",{class:"title-ref"},"script")," work, they need to be added to the",(0,a.kt)("span",{class:"title-ref"},"GreedySearchDecoder"),"'s constructor:",(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"self._device = device\nself._SOS_token = SOS_token\n")),(0,a.kt)("p",null,"and referred to as ",(0,a.kt)("span",{class:"title-ref"},"self.","_","device")," and"),(0,a.kt)("span",{class:"title-ref"},"self.\\_SOS\\_token")," instead of ",(0,a.kt)("span",{class:"title-ref"},"device")," and ",(0,a.kt)("span",{class:"title-ref"},"SOS\\_token")," in the ",(0,a.kt)("span",{class:"title-ref"},"GreedySearchDecoder"),"'s ",(0,a.kt)("span",{class:"title-ref"},"forward")," method.",(0,a.kt)("h3",{id:"3-runtimeerror-all-inputs-of-range-must-be--found-tensor-inferred-in-argument"},"3. RuntimeError ",(0,a.kt)("span",{class:"title-ref"},"all inputs of range must be '...', found Tensor (inferred) in argument")),(0,a.kt)("p",null,"The error message continues with: ",(0,a.kt)("span",{class:"title-ref"},"add type\ndefinitions for each of the module's forward method arguments. Because\nall parameters to a TorchScript function are of the\n","`","torch.Tensor")," type by default, you need to specifically declare\nthe type for each parameter that is not of type 'Tensor'. For a complete\nlist of TorchScript-supported types, see\n",(0,a.kt)("a",{parentName:"p",href:"https://pytorch.org/docs/master/jit_language_reference.html#supported-type"},"here"),"."),(0,a.kt)("p",null,"For example, the ",(0,a.kt)("span",{class:"title-ref"},"GreedySearchDecoder"),"'s"),(0,a.kt)("span",{class:"title-ref"},"forward")," method signature needs to be changed from:",(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"def forward(self, input_seq, input_length, max_length):\n")),(0,a.kt)("p",null,"to:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"def forward(self, input_seq, input_length, max_length : int):\n")),(0,a.kt)("p",null,"After using the ",(0,a.kt)("span",{class:"title-ref"},"trace")," or ",(0,a.kt)("span",{class:"title-ref"},"script")," method above, and fixing possible\nerrors, you should have a TorchScript model ready to be optimized for\nmobile."),(0,a.kt)("h2",{id:"optimize-a-torchscript-model"},"Optimize a TorchScript Model"),(0,a.kt)("p",null,"Simply run the following code snippet to optimize a TorchScript model\ngenerated with the ",(0,a.kt)("span",{class:"title-ref"},"trace")," and/or ",(0,a.kt)("span",{class:"title-ref"},"script")," method:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"from torch.utils.mobile_optimizer import optimize_for_mobile\noptimized_torchscript_model = optimize_for_mobile(torchscript_model)\n")),(0,a.kt)("p",null,"The optimized model can then be saved and deployed in mobile apps:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'optimized_torchscript_model.save("optimized_torchscript_model.pth")\n')),(0,a.kt)("p",null,"By default, ",(0,a.kt)("span",{class:"title-ref"},"optimize","_","for","_","mobile")," will\nperform the following types of optimizations:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Conv2D and BatchNorm fusion which folds Conv2d-BatchNorm2d into\nConv2d;"),(0,a.kt)("li",{parentName:"ul"},"Insert and fold prepacked ops which rewrites the model graph to\nreplace 2D convolutions and linear ops with their prepacked\ncounterparts."),(0,a.kt)("li",{parentName:"ul"},"ReLU and hardtanh fusion which rewrites graph by finding\nReLU/hardtanh ops and fuses them together."),(0,a.kt)("li",{parentName:"ul"},"Dropout removal which removes dropout nodes from this module when\ntraining is false.")),(0,a.kt)("h2",{id:"learn-more"},"Learn More"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"The official ",(0,a.kt)("a",{parentName:"li",href:"https://pytorch.org/docs/stable/jit_language_reference.html"},"TorchScript Language\nReference"),"."),(0,a.kt)("li",{parentName:"ol"},"The ",(0,a.kt)("span",{class:"title-ref"},"torch.utils.mobile","_","optimizer"),(0,a.kt)("a",{parentName:"li",href:"https://pytorch.org/docs/stable/mobile_optimizer.html"},"API\ndocumentation"),".")))}h.isMDXComponent=!0}}]);