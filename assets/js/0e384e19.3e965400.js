(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[671],{3905:function(e,t,r){"use strict";r.d(t,{Zo:function(){return c},kt:function(){return d}});var o=r(7294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,o)}return r}function a(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,o,n=function(e,t){if(null==e)return{};var r,o,n={},i=Object.keys(e);for(o=0;o<i.length;o++)r=i[o],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(o=0;o<i.length;o++)r=i[o],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var p=o.createContext({}),s=function(e){var t=o.useContext(p),r=t;return e&&(r="function"==typeof e?e(t):a(a({},t),e)),r},c=function(e){var t=s(e.components);return o.createElement(p.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},m=o.forwardRef((function(e,t){var r=e.components,n=e.mdxType,i=e.originalType,p=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),m=s(r),d=n,h=m["".concat(p,".").concat(d)]||m[d]||u[d]||i;return r?o.createElement(h,a(a({ref:t},c),{},{components:r})):o.createElement(h,a({ref:t},c))}));function d(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=r.length,a=new Array(i);a[0]=m;var l={};for(var p in t)hasOwnProperty.call(t,p)&&(l[p]=t[p]);l.originalType=e,l.mdxType="string"==typeof e?e:n,a[1]=l;for(var s=2;s<i;s++)a[s]=r[s];return o.createElement.apply(null,a)}return o.createElement.apply(null,r)}m.displayName="MDXCreateElement"},426:function(e,t,r){"use strict";r.r(t),r.d(t,{frontMatter:function(){return l},contentTitle:function(){return p},metadata:function(){return s},toc:function(){return c},default:function(){return m}});var o=r(2122),n=r(9756),i=(r(7294),r(3905)),a=["components"],l={slug:"/",sidebar_position:1},p="PyTorch Mobile",s={unversionedId:"intro",id:"intro",isDocsHomePage:!1,title:"PyTorch Mobile",description:"There is a growing need to execute ML models on edge devices to reduce latency, preserve privacy, and enable new interactive use cases.",source:"@site/docs/intro.md",sourceDirName:".",slug:"/",permalink:"/docs/",editUrl:"https://github.com/facebook/docusaurus/edit/master/website/docs/intro.md",version:"current",sidebarPosition:1,frontMatter:{slug:"/",sidebar_position:1},sidebar:"tutorialSidebar",next:{title:"Hello World!",permalink:"/docs/helloworld"}},c=[{value:"Key features",id:"key-features",children:[]},{value:"Prototypes",id:"prototypes",children:[]},{value:"Deployment workflow",id:"deployment-workflow",children:[]},{value:"Examples to get you started",id:"examples-to-get-you-started",children:[]},{value:"Demo apps",id:"demo-apps",children:[]}],u={toc:c};function m(e){var t=e.components,l=(0,n.Z)(e,a);return(0,i.kt)("wrapper",(0,o.Z)({},u,l,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"pytorch-mobile"},"PyTorch Mobile"),(0,i.kt)("p",null,"There is a growing need to execute ML models on edge devices to reduce latency, preserve privacy, and enable new interactive use cases."),(0,i.kt)("p",null,"The PyTorch Mobile runtime beta release allows you to seamlessly go from training a model to deploying it, while staying entirely within the PyTorch ecosystem. It provides an end-to-end workflow that simplifies the research to production environment for mobile devices. In addition, it paves the way for privacy-preserving features via federated learning techniques."),(0,i.kt)("p",null,"PyTorch Mobile is in beta stage right now, and is already in wide scale production use. It will soon be available as a stable release once the APIs are locked down."),(0,i.kt)("h2",{id:"key-features"},"Key features"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Available for ",(0,i.kt)("a",{parentName:"li",href:"%7B%7Bsite.baseurl%7D%7D/mobile/ios"},"iOS"),", ",(0,i.kt)("a",{parentName:"li",href:"%7B%7Bsite.baseurl%7D%7D/mobile/android"},"Android")," and Linux"),(0,i.kt)("li",{parentName:"ul"},"Provides APIs that cover common preprocessing and integration tasks needed for incorporating ML in mobile applications"),(0,i.kt)("li",{parentName:"ul"},"Support for tracing and scripting via TorchScript IR"),(0,i.kt)("li",{parentName:"ul"},"Support for XNNPACK floating point kernel libraries for Arm CPUs"),(0,i.kt)("li",{parentName:"ul"},"Integration of QNNPACK for 8-bit quantized kernels. Includes support for per-channel quantization, dynamic quantization and more"),(0,i.kt)("li",{parentName:"ul"},"Provides an ",(0,i.kt)("a",{parentName:"li",href:"https://pytorch.org/tutorials/recipes/mobile_interpreter.html"},"efficient mobile interpreter in Android and iOS"),". Also supports build level optimization and selective compilation depending on the operators needed for user applications (i.e., the final binary size of the app is determined by the actual operators the app needs)."),(0,i.kt)("li",{parentName:"ul"},"Streamline model optimization via optimize_for_mobile"),(0,i.kt)("li",{parentName:"ul"},"Support for hardware backends like GPU, DSP, and NPU will be available soon in Beta")),(0,i.kt)("h2",{id:"prototypes"},"Prototypes"),(0,i.kt)("p",null,"We have launched the following features in prototype, available in the PyTorch nightly releases, and would love to get your feedback on the ",(0,i.kt)("a",{parentName:"p",href:"https://discuss.pytorch.org/c/mobile/18"},"PyTorch forums"),":"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"GPU support on ",(0,i.kt)("a",{parentName:"li",href:"https://pytorch.org/tutorials/prototype/ios_gpu_workflow.html"},"iOS via Metal")),(0,i.kt)("li",{parentName:"ul"},"GPU support on ",(0,i.kt)("a",{parentName:"li",href:"https://pytorch.org/tutorials/prototype/vulkan_workflow.html"},"Android via Vulkan")),(0,i.kt)("li",{parentName:"ul"},"DSP and NPU support on Android via ",(0,i.kt)("a",{parentName:"li",href:"https://pytorch.org/tutorials/prototype/nnapi_mobilenetv2.html"},"Google NNAPI"))),(0,i.kt)("h2",{id:"deployment-workflow"},"Deployment workflow"),(0,i.kt)("p",null,"A typical workflow from training to mobile deployment with the optional model optimization steps is outlined in the following figure."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Docs Version Dropdown",src:r(5740).Z})),(0,i.kt)("h2",{id:"examples-to-get-you-started"},"Examples to get you started"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=amTepUIR93k"},"PyTorch Mobile Runtime for iOS")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=5Lxuu16_28o"},"PyTorch Mobile Runtime for Android")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://pytorch.org/tutorials/recipes/ptmobile_recipes_summary.html"},"PyTorch Mobile Recipes in Tutorials")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://pytorch.org/tutorials/beginner/deeplabv3_on_ios.html"},"Image Segmentation DeepLabV3 on iOS")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://pytorch.org/tutorials/beginner/deeplabv3_on_android.html"},"Image Segmentation DeepLabV3 on Android")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/pytorch/ios-demo-app/tree/master/D2Go"},"D2Go Object Detection on iOS")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/pytorch/android-demo-app/tree/master/D2Go"},"D2Go Object Detection on Android")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/pytorch/ios-demo-app/tree/master/TorchVideo"},"PyTorchVideo on iOS")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/pytorch/android-demo-app/tree/master/TorchVideo"},"PyTorchVideo on Android")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/pytorch/ios-demo-app/tree/master/SpeechRecognition"},"Speech Recognition on iOS")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/pytorch/android-demo-app/tree/master/SpeechRecognition"},"Speech Recognition on Android")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/pytorch/ios-demo-app/tree/master/QuestionAnswering"},"Question Answering on iOS")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/pytorch/android-demo-app/tree/master/QuestionAnswering"},"Question Answering on Android"))),(0,i.kt)("h2",{id:"demo-apps"},"Demo apps"),(0,i.kt)("p",null,"Our new demo apps also include examples of image segmentation, object detection, neural machine translation,\nquestion answering, and vision transformers. They are available on both iOS and Android:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/pytorch/ios-demo-app"},"iOS demo apps")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/pytorch/android-demo-app"},"Android demo apps"))))}m.isMDXComponent=!0},5740:function(e,t,r){"use strict";t.Z=r.p+"assets/images/pytorch-mobile-98bf36247d95fd3a8c284da690449e57.png"}}]);